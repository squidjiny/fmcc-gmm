{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9f7a4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#필요한 모듈 import\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import glob\n",
    "import os\n",
    "import wave\n",
    "from scipy.io import wavfile\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.effects as effects\n",
    "import librosa.util\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3882f5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAW 파일을 WAV 파일로 변환하는 함수\n",
    "def convert_raw_to_wav(raw_filepath, wav_filepath):\n",
    "    sample_width = 2  # 16비트 샘플\n",
    "    sample_rate = 16000  # 샘플링 속도\n",
    "    num_channels = 1  # 모노 오디오\n",
    "\n",
    "    # RAW 파일 읽기\n",
    "    with open(raw_filepath, 'rb') as raw_file:\n",
    "        raw_data = raw_file.read()\n",
    "\n",
    "    # WAV 파일 생성\n",
    "    with wave.open(wav_filepath, 'wb') as wav_file:\n",
    "        wav_file.setsampwidth(sample_width)\n",
    "        wav_file.setframerate(sample_rate)\n",
    "        wav_file.setnchannels(num_channels)\n",
    "\n",
    "        # RAW 데이터를 WAV 파일에 쓰기\n",
    "        wav_file.writeframes(raw_data)\n",
    "        \n",
    "def extract_features(audio_path):\n",
    "    # 음성 신호 불러오기\n",
    "    sr=16000\n",
    "    audio, sr = librosa.load(audio_path, sr=sr)\n",
    "    n_fft = 8192  # 원하는 FFT 윈도우 크기\n",
    "    hop_length=4096\n",
    "    n_mfcc=75\n",
    "    fmin=0\n",
    "    fmax=8000\n",
    "    top_db=90\n",
    "\n",
    "    # 스케일 조정\n",
    "    max_amp = np.max(np.abs(audio))\n",
    "    scale_factor = 1.0 / max_amp\n",
    "    scaled_audio = audio * scale_factor\n",
    "     \n",
    "    # 스펙트로그램 평활화\n",
    "    norm_audio = librosa.util.normalize(scaled_audio)\n",
    "    \n",
    "    # RMS 정규화\n",
    "    rms = librosa.feature.rms(y=norm_audio)\n",
    "    normalized_audio = norm_audio / (np.max(rms) + 1e-8)\n",
    "  \n",
    "    # MFCC 추출\n",
    "    mfcc = librosa.feature.mfcc(y=normalized_audio, sr=sr, n_mfcc=n_mfcc, hop_length=hop_length, n_fft=n_fft, fmin=fmin, fmax=fmax)\n",
    "    \n",
    "    return mfcc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7e05e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#결과 재현을 위한 시드고정\n",
    "np.random.seed(0)\n",
    "\n",
    "# CTL 파일 경로\n",
    "ctl_file = '202301ml_fmcc/fmcc_train.ctl'\n",
    "\n",
    "# RAW 파일이 저장된 폴더 경로\n",
    "raw_folder = '202301ml_fmcc/raw16k/train/'\n",
    "\n",
    "# WAV 파일이 저장될 폴더 경로\n",
    "wav_folder = '202301ml_fmcc/raw16k/train/wavtrain/'\n",
    "\n",
    "# CTL 파일 읽기\n",
    "with open(ctl_file, 'r') as file:\n",
    "    filelist = [line.strip().replace('\\\\', '/') + '.raw' for line in file]\n",
    "\n",
    "#.raw형태의 학습 데이터를 .wav로 바꿔준 후 저장할 폴더 생성\n",
    "if os.path.exists(wav_folder) == False:\n",
    "    os.mkdir(wav_folder)\n",
    "    \n",
    "# RAW 파일을 WAV 파일로 변환\n",
    "for fileinfo in filelist:\n",
    "    raw_filepath = os.path.join(raw_folder, fileinfo)\n",
    "    wav_folder_name = wav_folder+fileinfo.split('/')[0]\n",
    "    if os.path.exists(wav_folder_name) == False:\n",
    "        os.mkdir(wav_folder_name)\n",
    "    wav_filename = os.path.splitext(fileinfo)[0] + '.wav'\n",
    "    wav_filepath = os.path.join(wav_folder, wav_filename)\n",
    "    convert_raw_to_wav(raw_filepath, wav_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10c3bfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 남성 음성 데이터셋\n",
    "males_dataset = []\n",
    "\n",
    "# 여성 음성 데이터셋\n",
    "females_dataset = []\n",
    "\n",
    "#train 데이터의 raw파일을 wav파일로 변환한 경로 저장\n",
    "folder_path = \"202301ml_fmcc/raw16k/train/wavtrain/\"\n",
    "prefix1 = \"M\"\n",
    "prefix2 = \"F\"\n",
    "extension = \"*.wav\"\n",
    "\n",
    "#위의 wav파일을 저장한 경로에서 남성 wav 파일의 데이터를 file_path1에 여자 wav 파일의 데이터를 file_path2에 순차적으로 저장\n",
    "file_paths1 = glob.glob(folder_path+ \"/**/\"+prefix1+extension, recursive=True)\n",
    "file_paths2 = glob.glob(folder_path+ \"/**/\"+prefix2+extension, recursive=True)\n",
    "\n",
    "#순차적으로 저장한 남성 wav 파일의 경로명을 males_dataset에 저장\n",
    "for file_path in file_paths1:\n",
    "    males_dataset.append(file_path)\n",
    "\n",
    "#순차적으로 저장한 어성 wav 파일의 경로명을 females_dataset\n",
    "for file_path in file_paths2:\n",
    "    females_dataset.append(file_path)\n",
    "\n",
    "\n",
    "# 위에서 저장한 남성 음성 .wav파일의 경로명을 읽어 .wav 데이터셋에 대해 전처리\n",
    "males_features = []\n",
    "for audio_path in males_dataset:\n",
    "    features = extract_features(audio_path)\n",
    "    males_features.append(features)\n",
    "    \n",
    "# 위에서 저장한 여성 음성 .wav파일의 경로명을 읽어 .wav 데이터셋에 대해 전처리\n",
    "females_features = []\n",
    "for audio_path in females_dataset:\n",
    "    features = extract_features(audio_path)\n",
    "    females_features.append(features)\n",
    "\n",
    "# 위에서 만든 남성과 여성 특성 벡터 파일을 합쳐주기 위해 패딩하는 과정\n",
    "mansize=max([np.shape(i)[1] for i in males_features])\n",
    "femalesize=max([np.shape(i)[1] for i in females_features])\n",
    "if(mansize > femalesize):\n",
    "    max_size= max([np.shape(i)[1] for i in males_features])\n",
    "else:\n",
    "    max_size = max([np.shape(i)[1] for i in females_features])\n",
    "    \n",
    "#남성, 여성 데이터셋 중 길이가 가장 긴 값으로 패딩을 해줌\n",
    "man_features = []\n",
    "for i in males_features:\n",
    "    current_size = np.shape(i)[1]\n",
    "    if current_size < max_size:\n",
    "        padding_size = max_size - current_size\n",
    "        padding = np.zeros((np.shape(i)[0], padding_size))\n",
    "        padded_array = np.concatenate((i, padding), axis=1)\n",
    "        man_features.append(padded_array)\n",
    "    else:\n",
    "        man_features.append(i)\n",
    "        \n",
    "#패딩을 끝낸 후 합쳐 주기 위해 ndarray로 변환\n",
    "males_features = np.array(man_features, dtype=object)\n",
    "\n",
    "\n",
    "woman_features=[]    \n",
    "for i in females_features:\n",
    "    current_size = np.shape(i)[1]\n",
    "    if current_size < max_size:\n",
    "        padding_size = max_size - current_size\n",
    "        padding = np.zeros((np.shape(i)[0], padding_size))\n",
    "        padded_array = np.concatenate((i, padding), axis=1)\n",
    "        woman_features.append(padded_array)\n",
    "    else:\n",
    "        woman_features.append(i)\n",
    "        \n",
    "#패딩을 끝낸 후 합쳐 주기 위해 ndarray로 변환\n",
    "females_features = np.array(woman_features, dtype=object)\n",
    "\n",
    "#패딩을 끝마친 남성과 여성 특성 데이터셋을 학습을 위해 합침\n",
    "all_features = np.concatenate((males_features, females_features), axis=0)\n",
    "\n",
    "#아래의 LDA 전처리를 하기 위해 남성을 0으로 여성을 1로 라벨링한 후 두 label데이터를 합침\n",
    "males_labels =  np.zeros(len(males_features))\n",
    "females_labels = np.ones(len(females_features))\n",
    "all_labels = np.concatenate((males_labels, females_labels), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "179300bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'max_size' (int)\n",
      "Stored 'lda' (LinearDiscriminantAnalysis)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리\n",
    "flattened_features = all_features.reshape(all_features.shape[0], -1)  # 3D 데이터를 2D로 변환\n",
    "\n",
    "# NaN 값이 있는 경우 0으로 대체\n",
    "flattened_features = np.nan_to_num(flattened_features, nan=0.0)\n",
    "\n",
    "# LDA를 통한 특성 변환\n",
    "n_components=1\n",
    "lda = LinearDiscriminantAnalysis(n_components=n_components)\n",
    "lda_features = lda.fit_transform(flattened_features, all_labels)\n",
    "\n",
    "# # GMM 모델 훈련\n",
    "n_clusters = 2  # 클러스터 개수 (성별 개수와 일치)\n",
    "gmm = GaussianMixture(n_components=n_clusters, covariance_type='full', random_state=0)\n",
    "gmm.fit(lda_features)\n",
    "\n",
    "#학습한 모델을 file_name으로 저장\n",
    "file_name = 'gmm_model.pkl'\n",
    "joblib.dump(gmm, file_name)\n",
    "\n",
    "#테스트용 코드에서 테스트 데이터의 패딩을 위해 max_szie와 위의 전처리에 사용한 lda 파라미터를 테스트용 코드에서 사용해주기 위해 저장\n",
    "%store max_size\n",
    "%store lda"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
